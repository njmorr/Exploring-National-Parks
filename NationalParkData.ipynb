{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to create file paths across operating systems\n",
    "import os\n",
    "import pandas as pd\n",
    "#postgress password\n",
    "from config import password\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trails = pd.read_csv(\"initialData/all_trails_data_national_park.csv\")\n",
    "\n",
    "csv_path = os.path.join(\"initialData\", \"recreation_visitation_by_state_and_by_park_\")\n",
    "year_2016 = pd.read_csv(f\"{csv_path}2016.csv\", low_memory=False)\n",
    "year_2015 = pd.read_csv(f\"{csv_path}2015.csv\", low_memory=False)\n",
    "year_2014 = pd.read_csv(f\"{csv_path}2014.csv\", low_memory=False)\n",
    "year_2013 = pd.read_csv(f\"{csv_path}2013.csv\", low_memory=False)\n",
    "year_2012 = pd.read_csv(f\"{csv_path}2012.csv\", low_memory=False)\n",
    "year_2011 = pd.read_csv(f\"{csv_path}2011.csv\", low_memory=False)\n",
    "year_2010 = pd.read_csv(f\"{csv_path}2010.csv\", low_memory=False)\n",
    "\n",
    "state_visitors = pd.read_csv(\"data/all_years_visitors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trail data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "df_trails = pd.DataFrame(all_trails)\n",
    "df_trails.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trails = df_trails[[\"trail_id\", \"name\", \"area_name\", \"state_name\", \"_geoloc\", \"popularity\", \"length\", \"difficulty_rating\", \"route_type\", \"visitor_usage\", \"avg_rating\", \"features\", \"activities\"]]\n",
    "df_trails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trails.to_csv(\"data//trail_data.csv\", encoding = \"utf-8\", index = False)\n",
    "df_trails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state, park, and visitor data to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "df_2016 = pd.DataFrame(year_2016)\n",
    "df_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "df_2016 = pd.DataFrame(year_2016)\n",
    "df_2016_data = df_2016[[\"State\", \"Field1\", \"Field2\", \"Textbox22\", \"RecVisitors1\", \"Textbox23\"]]\n",
    "\n",
    "\n",
    "#rename columns\n",
    "df_2016_data = df_2016_data.rename(columns = {'Field1': 'Park', 'Field2': 'ParkVisitorCount_2016', \n",
    "                                              'Textbox22': 'ParkPctChange_2016',\n",
    "                                              'RecVisitors1': 'StateVisitorCount_2016', 'Textbox23': 'StatePctChange_2016'})\n",
    "\n",
    "#add column of state and park\n",
    "df_2016_data[\"PK\"] = df_2016_data[\"State\"] + \" \" + df_2016_data[\"Park\"]\n",
    "\n",
    "\n",
    "#reorder columns\n",
    "df_2016_data = df_2016_data[['PK', 'State', 'Park', 'ParkVisitorCount_2016', 'ParkPctChange_2016',\n",
    "                             'StateVisitorCount_2016', 'StatePctChange_2016']]\n",
    "\n",
    "#write data to CSV file\n",
    "df_2016_data.to_csv(\"data//2016_park_data.csv\", encoding = \"utf-8\", index = False)\n",
    "df_2016_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015\n",
    "df_2015 = pd.DataFrame(year_2015)\n",
    "\n",
    "df_2015_data = df_2015[[\"State\", \"Field1\", \"Field2\", \"Textbox22\", \"RecVisitors1\", \"Textbox23\"]]\n",
    "\n",
    "#add column for year\n",
    "#df_2015_data[\"Year\"] = \"2015\"\n",
    "\n",
    "df_2015_data = df_2015_data.rename(columns = { 'Field1': 'Park', 'Field2': 'ParkVisitorCount_2015', \n",
    "                                              'Textbox22': 'ParkPctChange_2015',\n",
    "                                              'RecVisitors1': 'StateVisitorCount_2015', 'Textbox23': 'StatePctChange_2015'})\n",
    "#add column of state and park\n",
    "df_2015_data[\"PK\"] = df_2015_data[\"State\"] + \" \" + df_2015_data[\"Park\"]\n",
    "\n",
    "#reorder columns\n",
    "df_2015_data = df_2015_data[['PK', 'ParkVisitorCount_2015', 'ParkPctChange_2015',\n",
    "                             'StateVisitorCount_2015', 'StatePctChange_2015']]\n",
    "\n",
    "df_2015_data.to_csv(\"data//2015_park_data.csv\", encoding = \"utf-8\", index = False)\n",
    "df_2015_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "df_2014 = pd.DataFrame(year_2014)\n",
    "df_2014_data = df_2014[[\"State\", \"Field1\", \"Field2\", \"Textbox22\", \"RecVisitors1\", \"Textbox23\"]]\n",
    "\n",
    "#add column for year\n",
    "#df_2014_data[\"Year\"] = \"2014\"\n",
    "\n",
    "df_2014_data = df_2014_data.rename(columns = { 'Field1': 'Park', 'Field2': 'ParkVisitorCount_2014', \n",
    "                                              'Textbox22': 'ParkPctChange_2014',\n",
    "                                              'RecVisitors1': 'StateVisitorCount_2014', 'Textbox23': 'StatePctChange_2014'})\n",
    "\n",
    "#add column of state and park\n",
    "df_2014_data[\"PK\"] = df_2014_data[\"State\"] + \" \" + df_2014_data[\"Park\"]\n",
    "\n",
    "#reorder columns\n",
    "df_2014_data = df_2014_data[['PK', 'ParkVisitorCount_2014', 'ParkPctChange_2014',\n",
    "                             'StateVisitorCount_2014', 'StatePctChange_2014']]\n",
    "\n",
    "df_2014_data.to_csv(\"data//2014_park_data.csv\", encoding = \"utf-8\", index = False)\n",
    "df_2014_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all years together into one dataframe\n",
    "df_all_years = pd.merge(df_2016_data, df_2015_data, on = \"PK\", how = \"outer\")\n",
    "df_all_years = pd.merge(df_all_years, df_2014_data, on = \"PK\", how = \"outer\")\n",
    "df_all_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows for non US states\n",
    "\n",
    "# get names of indexes for which column State has value of not us state and drop those rows\n",
    "index_names = df_all_years[df_all_years['State'] == \"American Samoa\"].index\n",
    "df_all_years.drop(index_names, inplace = True)\n",
    "\n",
    "index_names = df_all_years[df_all_years['State'] == \"District of Columbia\"].index\n",
    "df_all_years.drop(index_names, inplace = True)\n",
    "\n",
    "index_names = df_all_years[df_all_years['State'] == \"Guam\"].index\n",
    "df_all_years.drop(index_names, inplace = True)\n",
    "\n",
    "index_names = df_all_years[df_all_years['State'] == \"Puerto Rico\"].index\n",
    "df_all_years.drop(index_names, inplace = True)\n",
    "\n",
    "index_names = df_all_years[df_all_years['State'] == \"Virgin Islands\"].index\n",
    "df_all_years.drop(index_names, inplace = True)\n",
    "\n",
    "\n",
    "df_all_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_years['ParkVisitorCount_2016'] = df_all_years['ParkVisitorCount_2016'].astype(str).str.replace(',', '').astype(float)\n",
    "df_all_years['ParkVisitorCount_2015'] = df_all_years['ParkVisitorCount_2015'].astype(str).str.replace(',', '').astype(float)\n",
    "df_all_years['ParkVisitorCount_2014'] = df_all_years['ParkVisitorCount_2014'].astype(str).str.replace(',', '').astype(float)\n",
    "df_all_years['ParkPctChange_2016'] = df_all_years['ParkPctChange_2016'].astype(str).str.replace('%', '').astype(float)\n",
    "df_all_years['ParkPctChange_2015'] = df_all_years['ParkPctChange_2015'].astype(str).str.replace('%', '').astype(float)\n",
    "df_all_years['ParkPctChange_2014'] = df_all_years['ParkPctChange_2014'].astype(str).str.replace('%', '').astype(float)\n",
    "df_all_years['StateVisitorCount_2016'] = df_all_years['StateVisitorCount_2016'].astype(str).str.replace(',', '').astype(float)\n",
    "df_all_years['StateVisitorCount_2015'] = df_all_years['StateVisitorCount_2015'].astype(str).str.replace(',', '').astype(float)\n",
    "df_all_years['StateVisitorCount_2014'] = df_all_years['StateVisitorCount_2014'].astype(str).str.replace(',', '').astype(float)\n",
    "df_all_years['StatePctChange_2016'] = df_all_years['StatePctChange_2016'].astype(str).str.replace('%', '').astype(float)\n",
    "df_all_years['StatePctChange_2015'] = df_all_years['StatePctChange_2015'].astype(str).str.replace('%', '').astype(float)\n",
    "df_all_years['StatePctChange_2014'] = df_all_years['StatePctChange_2014'].astype(str).str.replace('%', '').astype(float)\n",
    "\n",
    "df_all_years.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_years.fillna(0)\n",
    "df_all_years[\"ParkPctChange_2016\"] = df_all_years[\"ParkPctChange_2016\"].fillna(0)\n",
    "df_all_years[\"ParkPctChange_2015\"] = df_all_years[\"ParkPctChange_2015\"].fillna(0)\n",
    "df_all_years[\"ParkPctChange_2014\"] = df_all_years[\"ParkPctChange_2014\"].fillna(0)\n",
    "df_all_years[\"ParkVisitorCount_2016\"] = df_all_years[\"ParkVisitorCount_2016\"].fillna(0)\n",
    "df_all_years[\"ParkVisitorCount_2015\"] = df_all_years[\"ParkVisitorCount_2015\"].fillna(0)\n",
    "df_all_years[\"ParkVisitorCount_2014\"] = df_all_years[\"ParkVisitorCount_2014\"].fillna(0)\n",
    "df_all_years.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_visitors_df = df_all_years.loc[df_all_years[\"ParkVisitorCount_2014\"].isna()==True]\n",
    "park_visitors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_years.to_csv(\"data//all_years_state_park.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trails.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_visitors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_visitors['StateVisitorCount_2016'] = state_visitors['StateVisitorCount_2016'].astype(str).str.replace(',', '').astype(float)\n",
    "state_visitors['StateVisitorCount_2015'] = state_visitors['StateVisitorCount_2015'].astype(str).str.replace(',', '').astype(float)\n",
    "state_visitors['StateVisitorCount_2014'] = state_visitors['StateVisitorCount_2014'].astype(str).str.replace(',', '').astype(float)\n",
    "state_visitors['StatePctChange_2016'] = state_visitors['StatePctChange_2016'].astype(str).str.replace('%', '').astype(float)\n",
    "state_visitors['StatePctChange_2015'] = state_visitors['StatePctChange_2015'].astype(str).str.replace('%', '').astype(float)\n",
    "state_visitors['StatePctChange_2014'] = state_visitors['StatePctChange_2014'].astype(str).str.replace('%', '').astype(float)\n",
    "\n",
    "state_visitors.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into the postgres database!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a database in pgAdmin\n",
    "#create tables and load data to tables\n",
    "engine = create_engine(f'postgresql://postgres:{password}@localhost:5432/national_park_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_years.to_sql(name = 'state_parks', con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trails.to_sql(name = 'trails', con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_visitors.to_sql(name = 'state_visitors', con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON Magic below!!  Running the cells below this point is unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the visitor count information to the GeoJSON file because d3.json loops cause pain.\n",
    "filename = \"./static/data/gz_2010_us_040_00_5m.json\"\n",
    "\n",
    "geojson_df = pd.read_json(filename)\n",
    "geojson_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the source GeoJSON file, keep all of the data in the right format\n",
    "# and add the desired data from the state_visitors dataframe to the properties for each state\n",
    "# maintaining the correct relationships between all of the data thingies.\n",
    "geojson_df['features']\n",
    "\n",
    "features_list = []\n",
    "for label, content in geojson_df['features'].items():\n",
    "    #print(f'label: {label}')\n",
    "    #print(f'content: {content.items() }')\n",
    "    new_data = {}\n",
    "    count = 0\n",
    "   \n",
    "    for key, value in content.items():\n",
    "        #print(key)\n",
    "        #print(value)\n",
    "        \n",
    "        geo_dict = {}\n",
    "        if key == 'type':\n",
    "            new_data.update({key: value})\n",
    "            \n",
    "        if key == 'geometry':\n",
    "            new_data.update({key: value})      \n",
    "        \n",
    "        if key == 'properties':\n",
    "            \n",
    "            print(value['NAME'])\n",
    "            # use the state name to grab the data from the state_visitors dataframe!\n",
    "            state = value['NAME']           \n",
    "            \n",
    "            for i, d in value.items():\n",
    "                print(i)\n",
    "                print(d)\n",
    "                dict = {i: d}\n",
    "                geo_dict.__setitem__(i,d)\n",
    "            \n",
    "            # colorful variable names happen at 1:00 am in the morning, some of them live on\n",
    "            WOAH = state_visitors.loc[state_visitors['State'] == state].to_dict(orient='list')\n",
    "            print(f'WOAH: {WOAH}')  # this is a dictionary of lists (each with a single item)\n",
    "            for i, d in WOAH.items():\n",
    "                print(d[0])\n",
    "                dict = {i: d[0]}\n",
    "                geo_dict.__setitem__(i, d[0])\n",
    "#                 print(d)\n",
    "            \n",
    "            #print(f'WOAH: {WOAH}')\n",
    "#             geo_dict[\"State\"] = state\n",
    "#             geo_dict[\"StateVisitorCount_2016\"] = state_visitors.loc[state_visitors['State'] == state]['StateVisitorCount_2016'][0]\n",
    "#             geo_dict[\"StatePctChange_2016\"] = state_visitors.loc[state_visitors['State'] == state]['StatePctChange_2016'][0]\n",
    "#             geo_dict[\"StateVisitorCount_2015\"] = state_visitors.loc[state_visitors['State'] == state]['StateVisitorCount_2015'][0]\n",
    "#             geo_dict[\"StatePctChange_2015\"] = state_visitors.loc[state_visitors['State'] == state]['StatePctChange_2015'][0]\n",
    "#             geo_dict[\"StateVisitorCount_2014\"] = state_visitors.loc[state_visitors['State'] == state]['StateVisitorCount_2014'][0]\n",
    "#             geo_dict[\"StatePctChange_2014\"] = state_visitors.loc[state_visitors['State'] == state]['StatePctChange_2014'][0]\n",
    "            \n",
    "#             print(f'{key}: and {dict}')\n",
    "            new_data.update({key: geo_dict})\n",
    "            count = count +1\n",
    "            \n",
    "    features_list.append(new_data)  \n",
    "#print(f'new data: ${new_data}')\n",
    "\n",
    "new_geojson_data = {'type': \"FeatureCollection\",\n",
    "        'features': features_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geojson_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geojson_df = pd.DataFrame(new_geojson_data)\n",
    "#new_geojson_df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the new geojson file!\n",
    "output_filename = './static/data/parks_geojson.js'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    json.dump(new_geojson_data, output_file, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
